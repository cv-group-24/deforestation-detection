{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# TODO: Handle relative paths correctly so we can all run it independantly and add to the readme where the dataset needs to be stored\n",
    "dataset_path = r\"C:\\Users\\chris\\Desktop\\University\\Code\\ComputerVision\\ForestNetDataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'Grassland shrubland': 0, 'Other': 1, 'Plantation': 2, 'Smallholder agriculture': 3}\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Join the directory with each CSV filename.\n",
    "test_path = os.path.join(dataset_path, \"test.csv\")\n",
    "train_path = os.path.join(dataset_path, \"train.csv\")\n",
    "validation_path = os.path.join(dataset_path, \"val.csv\")\n",
    "\n",
    "# Read the CSV files into pandas DataFrames.\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(validation_path)\n",
    "\n",
    "# Create a mapping from the string labels to integers based on the training data.\n",
    "labels = sorted(train_df[\"merged_label\"].unique())\n",
    "label_to_index = {label: idx for idx, label in enumerate(labels)}\n",
    "print(\"Label mapping:\", label_to_index)\n",
    "\n",
    "\n",
    "# FOR MODEL DEVELOPMENT JUST USE THE FIRST 128 SAMPLES FROM THE TRAINING SET\n",
    "train_df = train_df.head(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define DataLoaders for the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This class implements the function __getitem__ which means it can be passed into the DataLoader class from pytorch \n",
    "# which makes the batch processing much more seamless.\n",
    "class ForestNetDataset(Dataset):\n",
    "    def __init__(self, df, dataset_path, transform=None, label_map=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame containing the image paths and labels.\n",
    "            dataset_path (str): The base directory for the images.\n",
    "            transform (callable, optional): A function/transform to apply to the images.\n",
    "            label_map (dict, optional): Mapping from label names to integers.\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            row = self.df.iloc[idx]\n",
    "            image_rel_path = row[\"example_path\"] + \"/images/visible/composite.png\"\n",
    "            image_path = os.path.join(self.dataset_path, image_rel_path)\n",
    "            # Debug: print the image_path to see if it looks correct\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            label = row[\"merged_label\"]\n",
    "            if self.label_map is not None:\n",
    "                label = self.label_map[label]\n",
    "            return image, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx} from path {image_path}: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "# --- Image Transforms ---\n",
    "# Resize images to 224x224, convert them to tensors, and normalize.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "\n",
    "    # TODO: Look into calculating these values for our dataset. It probably has a lot more green than other\n",
    "    # datasets.\n",
    "    # These normalization values are typical for natural images.\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# --- Create Datasets and DataLoaders ---\n",
    "train_dataset = ForestNetDataset(train_df, dataset_path, transform=transform, label_map=label_to_index)\n",
    "test_dataset = ForestNetDataset(test_df, dataset_path, transform=transform, label_map=label_to_index)\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "# TO DO: Experiment with different num_workers (I don't know what this does)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/10, Loss: 1.3662\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 2/10, Loss: 1.3127\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 3/10, Loss: 1.2951\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 4/10, Loss: 1.3030\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 5/10, Loss: 1.2902\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 6/10, Loss: 1.2608\n",
      "Test Accuracy: 0.3862\n",
      "Epoch 7/10, Loss: 1.2332\n",
      "Test Accuracy: 0.4027\n",
      "Epoch 8/10, Loss: 1.2013\n",
      "Test Accuracy: 0.3488\n",
      "Epoch 9/10, Loss: 1.1516\n",
      "Test Accuracy: 0.3937\n",
      "Epoch 10/10, Loss: 1.1175\n",
      "Test Accuracy: 0.3922\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a CNN with input images sized 256x256\n",
    "# TO DO: Define a different CNN archtecture for different image sizes eg. 512 and 1024\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Convolutional Block 1: Input 3 x 256 x 256 -> Output 16 x 256 x 256, then maxpool to 16 x 128 x 128\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Convolutional Block 2: 16 x 128 x 128 -> 32 x 128 x 128, then maxpool to 32 x 64 x 64\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Convolutional Block 3: 32 x 64 x 64 -> 64 x 64 x 64, then maxpool to 64 x 32 x 32\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64 * 32 * 32, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the features for the classifier\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Assume the number of classes is determined by your label mapping:\n",
    "num_classes = len(label_to_index)\n",
    "model = SimpleCNN(num_classes)\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training and Evaluation Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()           # Zero the gradients\n",
    "        outputs = model(images)         # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()                 # Backward pass\n",
    "        optimizer.step()                # Update weights\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping to convert indices back to labels (for display purposes)\n",
    "index_to_label = {v: k for k, v in label_to_index.items()}\n",
    "target_names = [index_to_label[i] for i in range(num_classes)]\n",
    "\n",
    "# Collect predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()  # set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Print classification report (includes precision, recall, and F1 score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=target_names, digits=4))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChrisEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
